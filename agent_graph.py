import os
import re
from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from rag_setup import get_retriever
from pdf_gen import generate_permit_pdf

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o", temperature=0)
retriever = get_retriever()


# --- í”„ë¡¬í”„íŠ¸ ë¡œë” í•¨ìˆ˜ ---
def load_prompt(filename, **kwargs):
    """
    prompts í´ë”ì˜ md íŒŒì¼ì„ ì½ì–´ì„œ ë³€ìˆ˜({key})ë¥¼ ì±„ì›Œì£¼ëŠ” í•¨ìˆ˜
    """
    file_path = os.path.join("prompts", filename)
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            # íŒŒì¼ ë‚´ìš©ì— ë³€ìˆ˜ê°’ ì£¼ì… (format ì‚¬ìš©)
            return content.format(**kwargs)
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
        return ""


# --- 1. ìƒíƒœ(State) ì •ì˜ ---
class AgentState(TypedDict):
    user_input: str
    chat_history: str
    messages: List[str]
    context: str
    risk_level: str
    risk_score: int
    final_output: str
    pdf_path: str
    needs_more_info: bool


# --- 2. ë…¸ë“œ(Agent) ì •ì˜ ---


def coordinator(state: AgentState):
    """Main Orchestrator: ì˜ë„ íŒŒì•… ë° ì •ë³´ ë³‘í•©"""
    print("ğŸ¤– [Coordinator] ì§€ëŠ¥í˜• ë¶„ì„ ì¤‘...")

    # [ìˆ˜ì •] íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = load_prompt(
        "coordinator.md",
        chat_history=state.get("chat_history", "ì—†ìŒ"),
        user_input=state["user_input"],
    )

    response = llm.invoke([HumanMessage(content=prompt)]).content

    if response.startswith("MISSING"):
        question = response.replace("MISSING:", "").strip()
        return {"needs_more_info": True, "messages": [question]}

    return {"needs_more_info": False}


def regulation_finder(state: AgentState):
    print("ğŸ“š [Regulation Agent] ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")

    current_input = state["user_input"]
    history = state.get("chat_history", "")
    # ëŒ€í™” ê¸°ë¡ê³¼ í˜„ì¬ ì…ë ¥ì„ í•©ì³ì„œ ì „ì²´ ë§¥ë½ íŒŒì•…
    full_context = f"{history} {current_input}"

    # ---------------------------------------------------------
    # [1] í™”í•™ë¬¼ì§ˆ ì •ë°€ íƒ€ê²ŸíŒ… (íŒŒì¼ëª… í•„í„°ë§)
    # ---------------------------------------------------------
    target_chemicals = ["í†¨ë£¨ì—”", "ë²¤ì  ", "ì•„ì„¸í†¤", "í™©ì‚°", "ì—¼ì‚°", "ìˆ˜ì†Œ", "ì§ˆì†Œ"]
    detected_chem = ""

    # ë¬¸ë§¥ ì „ì²´ì—ì„œ í™”í•™ë¬¼ì§ˆ ê°ì§€
    for chem in target_chemicals:
        if chem in full_context:
            detected_chem = chem
            break

    docs_msds = []
    if detected_chem:
        print(f"ğŸ¯ í™”í•™ë¬¼ì§ˆ ê°ì§€: {detected_chem} -> íŒŒì¼ëª… ì¼ì¹˜ ë¬¸ì„œë§Œ ì„ ë³„")
        q_msds = f"{detected_chem} MSDS ë¬¼ì§ˆì•ˆì „ë³´ê±´ìë£Œ ê²½ê³ í‘œì§€"
        raw_msds_docs = retriever.invoke(q_msds)

        # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ íŒŒì¼ëª…ì— ì‹¤ì œ 'ë¬¼ì§ˆëª…'ì´ í¬í•¨ëœ ê²ƒë§Œ ë‚¨ê¹€
        for doc in raw_msds_docs:
            filename = os.path.basename(doc.metadata.get("source", ""))
            if detected_chem in filename:
                docs_msds.append(doc)

    # ---------------------------------------------------------
    # [2] ì‚¬ë‚´ ê·œì • (S-Chem) ë…ë¦½ ê²€ìƒ‰
    # ---------------------------------------------------------
    print("ğŸ¢ ì‚¬ë‚´ ê·œì •(S-Chem) ê²€ìƒ‰")
    q_sop = "S Chem Safety Regulation_v2 ì‚¬ë‚´ ì•ˆì „ ì‘ì—… í—ˆê°€ ì§€ì¹¨ ì ˆì°¨"
    docs_sop = retriever.invoke(q_sop)

    # ---------------------------------------------------------
    # [3] ë²•ë ¹ ë° ê°€ì´ë“œ (ìƒí™©ë³„ í‚¤ì›Œë“œ ì£¼ì…)
    # ---------------------------------------------------------
    if any(keyword in full_context for keyword in ["íƒ±í¬", "ë°€í", "ì²­ì†Œ", "ë§¨í™€"]):
        print("ğŸ•³ï¸ ë°€íê³µê°„/íƒ±í¬ ì‘ì—… ê°ì§€ -> ê¸°ìˆ ì§€ì¹¨ ê²€ìƒ‰ ê°•í™”")
        q_gen = f"ë°€íê³µê°„ ì‘ì—… í”„ë¡œê·¸ë¨ ìˆ˜ë¦½ ë° ì‹œí–‰ì— ê´€í•œ ê¸°ìˆ ì§€ì¹¨ {current_input}"
    else:
        print("âš–ï¸ ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰")
        q_gen = f"ì‚°ì—…ì•ˆì „ë³´ê±´ë²• ì•ˆì „ ë³´ê±´ ê·œì¹™ {current_input}"

    docs_gen = retriever.invoke(q_gen)

    # ---------------------------------------------------------
    # [4] ê²°ê³¼ ë³‘í•© (ìš°ì„ ìˆœìœ„: MSDS -> SOP -> ë²•ë ¹)
    # ---------------------------------------------------------
    combined_docs = []

    # 1ìˆœìœ„: í•„í„°ë§ëœ MSDS
    if docs_msds:
        combined_docs.extend(docs_msds[:2])

    # 2ìˆœìœ„: ì‚¬ë‚´ ê·œì • (SOP)
    if docs_sop:
        combined_docs.extend(docs_sop[:2])

    # 3ìˆœìœ„: ë²•ë ¹/ê¸°ìˆ ì§€ì¹¨
    if docs_gen:
        combined_docs.extend(docs_gen[:3])

    # ---------------------------------------------------------
    # [5] ì¤‘ë³µ ì œê±°
    # ---------------------------------------------------------
    seen_sources = set()
    unique_docs = []

    for doc in combined_docs:
        source = os.path.basename(doc.metadata.get("source", "unknown"))
        if source not in seen_sources:
            seen_sources.add(source)
            unique_docs.append(doc)

    # ìµœì¢… 6ê°œ ë¬¸ì„œ ì„ ì •
    final_docs = unique_docs[:6]

    # [ë””ë²„ê¹…] ìµœì¢… ì„ ì •ëœ ë¬¸ì„œ ëª©ë¡ ì¶œë ¥
    print("ğŸ” [ìµœì¢… ì„ ì • ë¬¸ì„œ ëª©ë¡]")
    for d in final_docs:
        print(f"   - {os.path.basename(d.metadata.get('source'))}")

    if not final_docs:
        return {"context": "ê´€ë ¨ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    # ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
    formatted_docs = []
    for doc in final_docs:
        filename = os.path.basename(doc.metadata.get("source", "íŒŒì¼_ì—†ìŒ"))
        content = doc.page_content.strip()
        formatted_docs.append(f"ğŸ“„ [ì¶œì²˜: {filename}]\n{content}")

    context_text = "\n\n---\n\n".join(formatted_docs)
    return {"context": context_text}


def risk_analyst(state: AgentState):
    """Fine-Kinney ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì •ëŸ‰ì  ìœ„í—˜ì„± í‰ê°€"""
    print("âš ï¸ [Risk Analyst] ìœ„í—˜ë„ ê³„ì‚° ì¤‘ (Fine-Kinney)...")

    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = load_prompt(
        "risk_analyst.md",
        chat_history=state.get("chat_history", "ì—†ìŒ"),
        user_input=state["user_input"],
        context=state["context"],
    )

    response = llm.invoke([HumanMessage(content=prompt)]).content

    try:
        # ì •ê·œí‘œí˜„ì‹ íŒŒì‹±
        p_match = re.search(r"P\s*[:=]\s*([\d\.]+)", response)
        e_match = re.search(r"E\s*[:=]\s*([\d\.]+)", response)
        c_match = re.search(r"C\s*[:=]\s*([\d\.]+)", response)
        r_match = re.search(r"R\s*[:=]\s*([\d\.]+)", response)

        p_score = float(p_match.group(1)) if p_match else 0
        e_score = float(e_match.group(1)) if e_match else 0
        c_score = float(c_match.group(1)) if c_match else 0

        if r_match:
            r_score = float(r_match.group(1))
        else:
            r_score = p_score * e_score * c_score

        type_match = re.search(r"ì¬í•´ìœ í˜•\s*[:=]\s*(.+)", response)
        accident_type = type_match.group(1).strip() if type_match else "ë³µí•© ìœ„í—˜"

        if r_score >= 320:
            level = "Very High"
        elif r_score >= 160:
            level = "High"
        elif r_score >= 70:
            level = "Medium"
        else:
            level = "Low"

        final_report = f"""
**ğŸ¯ Fine-Kinney ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼**
* **ì¬í•´ í˜•íƒœ:** {accident_type}
* **ê³„ì‚° ê³µì‹:** $Risk = P \\times E \\times C$
* **ìƒì„¸ ì ìˆ˜:**
    * ê°€ëŠ¥ì„±(P): **{p_score}**
    * ë…¸ì¶œë¹ˆë„(E): **{e_score}**
    * ê°•ë„(C): **{c_score}**
* **ìµœì¢… ìœ„í—˜ë„(R):** <span style='color:red; font-size:1.2em; font-weight:bold;'>{int(r_score)}ì </span> ({level})
"""
    except Exception as e:
        print(f"íŒŒì‹± ì—ëŸ¬: {e} / LLM ì‘ë‹µ: {response}")
        r_score = 0
        level = "Error"
        final_report = "ìœ„í—˜ì„± í‰ê°€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    return {
        "risk_score": int(r_score),
        "risk_level": level,
        "context": state["context"] + "\n\n" + final_report,
    }


def admin_agent(state: AgentState):
    """ìµœì¢… PDF ìƒì„± ë° ë©”ì‹œì§€ ì‘ì„± (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¶„ë¦¬ ë²„ì „)"""
    print("ğŸ“ [Admin Agent] ì‘ì—… ë‚´ìš© ìš”ì•½ ë° PDF ìƒì„± ì¤‘...")

    score = state["risk_score"]
    context = state["context"]
    history = state.get("chat_history", "")
    last_input = state["user_input"]

    # ------------------------------------------------------------------
    # [STEP 1] ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 'í†µí•© ì‘ì—… ë‚´ìš©' ìš”ì•½í•˜ê¸°
    # ------------------------------------------------------------------
    summary_prompt = load_prompt(
        "work_summary.md", history=history, last_input=last_input
    )

    # ë§Œì•½ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëŒ€ë¹„ìš© ì•ˆì „ì¥ì¹˜
    if not summary_prompt:
        summary_prompt = f"ëŒ€í™”ê¸°ë¡: {history}\në§ˆì§€ë§‰ì…ë ¥: {last_input}\nìœ„ ë‚´ìš©ì„ í¬í•¨í•´ ì‘ì—… ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´."

    # ì‘ì—… ì œëª©ì„ LLMì´ ë‹¤ì‹œ ì”ë‹ˆë‹¤.
    consolidated_work_info = (
        llm.invoke([HumanMessage(content=summary_prompt)])
        .content.replace('"', "")
        .strip()
    )
    print(f"ğŸ“Œ í†µí•©ëœ ì‘ì—… ë‚´ìš©: {consolidated_work_info}")

    # ------------------------------------------------------------------
    # [STEP 2] ìœ„í—˜ ìš”ì¸ ë¶„ì„
    # ------------------------------------------------------------------
    # admin_agent.md íŒŒì¼ ë¡œë“œ
    reasoning_prompt_content = load_prompt(
        "admin_agent.md",
        user_input=consolidated_work_info,
        context=context,
    )

    reason_summary = llm.invoke(
        [HumanMessage(content=reasoning_prompt_content)]
    ).content

    # ------------------------------------------------------------------
    # [STEP 3] PDF ìƒì„±
    # ------------------------------------------------------------------
    try:
        # ìš”ì•½ëœ ì‘ì—… ë‚´ìš©(consolidated_work_info)ì„ PDF ì œëª©ìœ¼ë¡œ ì „ë‹¬
        pdf_file = generate_permit_pdf(
            score, state["risk_level"], reason_summary, consolidated_work_info
        )
    except Exception as e:
        print(f"PDF ì—ëŸ¬: {e}")
        pdf_file = None

    # UI ë©”ì‹œì§€ ìƒì„±
    if score >= 160:
        short_msg = f"ğŸš¨ **ë°˜ë ¤ (High Risk / {score}ì )**\nìƒì„¸ ì‚¬ìœ ëŠ” PDF í™•ì¸ í•„ìš”."
    elif score >= 70:
        short_msg = (
            f"âš ï¸ **ì¡°ê±´ë¶€ ìŠ¹ì¸ (Medium Risk / {score}ì )**\nì•ˆì „ ì¡°ì¹˜ ì´í–‰ í›„ ì‘ì—… ê°€ëŠ¥."
        )
    else:
        short_msg = f"âœ… **ìŠ¹ì¸ (Low Risk / {score}ì )**\nì‘ì—… í—ˆê°€ì„œ ë°œê¸‰ ì™„ë£Œ."

    return {"final_output": short_msg, "pdf_path": pdf_file}


# --- 3. ê·¸ë˜í”„ ì—°ê²° ---
workflow = StateGraph(AgentState)
workflow.add_node("coordinator", coordinator)
workflow.add_node("regulation_finder", regulation_finder)
workflow.add_node("risk_analyst", risk_analyst)
workflow.add_node("admin_agent", admin_agent)
workflow.set_entry_point("coordinator")


def check_info(state):
    return "end" if state["needs_more_info"] else "next"


workflow.add_conditional_edges(
    "coordinator", check_info, {"end": END, "next": "regulation_finder"}
)
workflow.add_edge("regulation_finder", "risk_analyst")
workflow.add_edge("risk_analyst", "admin_agent")
workflow.add_edge("admin_agent", END)

app_graph = workflow.compile()
