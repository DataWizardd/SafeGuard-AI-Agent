import os
import shutil
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

DB_PATH = "./faiss_db"


def get_retriever():

    print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ (BAAI/bge-m3)...")
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

    # 1. ì´ë¯¸ ë§Œë“¤ì–´ì§„ DBê°€ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(DB_PATH):
        print("ğŸ’¾ ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
        try:
            vectorstore = FAISS.load_local(
                DB_PATH, embeddings, allow_dangerous_deserialization=True
            )

            return vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 6},
            )

            # mmr? (ì‹¤í—˜í•´ë³´ê¸°)
            # return vectorstore.as_retriever(
            #     search_type="mmr",
            #     search_kwargs={"k": 10, "fetch_k": 20},
            # )

        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ DB ë¡œë“œ ì‹¤íŒ¨ : {e}")
            print("ğŸ—‘ï¸ ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            shutil.rmtree(DB_PATH)  # í´ë” ì‚­ì œ

    # 2. ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    print("ğŸ”„ ìƒˆë¡œìš´ ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    if not os.path.exists("./data"):
        os.makedirs("./data")
        print("âš ï¸ 'data' í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return None

    documents = []
    for file in os.listdir("./data"):
        if file.endswith(".pdf"):
            print(f"   - ë¡œë”© ì¤‘: {file}")
            loader = PyPDFLoader(f"./data/{file}")
            docs = loader.load()
            documents.extend(docs)

    if not documents:
        print("âŒ ë¡œë“œí•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # 3. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    splits = text_splitter.split_documents(documents)

    # 4. ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥
    print("vectors ìƒì„± ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    vectorstore = FAISS.from_documents(splits, embeddings)
    vectorstore.save_local(DB_PATH)
    print("ğŸ‰ DB ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")

    # ë¦¬í„´ ì‹œì—ë„ ë™ì¼í•œ ê²€ìƒ‰ ì¡°ê±´ ì ìš©
    return vectorstore.as_retriever(
        search_type="similarity_score_threshold",
        search_kwargs={"score_threshold": 0.4, "k": 8},
    )


if __name__ == "__main__":
    get_retriever()
